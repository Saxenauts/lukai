// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: protobuf/tensorflow/core/framework/step_stats.proto

/*
	Package tensorflow is a generated protocol buffer package.

	It is generated from these files:
		protobuf/tensorflow/core/framework/step_stats.proto

	It has these top-level messages:
		AllocatorMemoryUsed
		NodeOutput
		MemoryStats
		NodeExecStats
		DeviceStepStats
		StepStats
*/
package tensorflow

import proto "github.com/gogo/protobuf/proto"
import fmt "fmt"
import math "math"
import tensorflow1 "github.com/d4l3k/pok/protobuf/tensorflow/core/framework"
import tensorflow4 "github.com/d4l3k/pok/protobuf/tensorflow/core/framework"

import fmt "fmt"
import strings "strings"
import reflect "reflect"

import io "io"

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion2 // please upgrade the proto package

type AllocatorMemoryUsed struct {
	AllocatorName string `protobuf:"bytes,1,opt,name=allocator_name,json=allocatorName,proto3" json:"allocator_name,omitempty"`
	// These are per-node allocator memory stats.
	TotalBytes int64 `protobuf:"varint,2,opt,name=total_bytes,json=totalBytes,proto3" json:"total_bytes,omitempty"`
	PeakBytes  int64 `protobuf:"varint,3,opt,name=peak_bytes,json=peakBytes,proto3" json:"peak_bytes,omitempty"`
	// The bytes that are not deallocated.
	LiveBytes int64 `protobuf:"varint,4,opt,name=live_bytes,json=liveBytes,proto3" json:"live_bytes,omitempty"`
	// These are snapshots of the overall allocator memory stats.
	// The number of live bytes currently allocated by the allocator.
	AllocatorBytesInUse int64 `protobuf:"varint,5,opt,name=allocator_bytes_in_use,json=allocatorBytesInUse,proto3" json:"allocator_bytes_in_use,omitempty"`
}

func (m *AllocatorMemoryUsed) Reset()                    { *m = AllocatorMemoryUsed{} }
func (*AllocatorMemoryUsed) ProtoMessage()               {}
func (*AllocatorMemoryUsed) Descriptor() ([]byte, []int) { return fileDescriptorStepStats, []int{0} }

func (m *AllocatorMemoryUsed) GetAllocatorName() string {
	if m != nil {
		return m.AllocatorName
	}
	return ""
}

func (m *AllocatorMemoryUsed) GetTotalBytes() int64 {
	if m != nil {
		return m.TotalBytes
	}
	return 0
}

func (m *AllocatorMemoryUsed) GetPeakBytes() int64 {
	if m != nil {
		return m.PeakBytes
	}
	return 0
}

func (m *AllocatorMemoryUsed) GetLiveBytes() int64 {
	if m != nil {
		return m.LiveBytes
	}
	return 0
}

func (m *AllocatorMemoryUsed) GetAllocatorBytesInUse() int64 {
	if m != nil {
		return m.AllocatorBytesInUse
	}
	return 0
}

// Output sizes recorded for a single execution of a graph node.
type NodeOutput struct {
	Slot              int32                          `protobuf:"varint,1,opt,name=slot,proto3" json:"slot,omitempty"`
	TensorDescription *tensorflow4.TensorDescription `protobuf:"bytes,3,opt,name=tensor_description,json=tensorDescription" json:"tensor_description,omitempty"`
}

func (m *NodeOutput) Reset()                    { *m = NodeOutput{} }
func (*NodeOutput) ProtoMessage()               {}
func (*NodeOutput) Descriptor() ([]byte, []int) { return fileDescriptorStepStats, []int{1} }

func (m *NodeOutput) GetSlot() int32 {
	if m != nil {
		return m.Slot
	}
	return 0
}

func (m *NodeOutput) GetTensorDescription() *tensorflow4.TensorDescription {
	if m != nil {
		return m.TensorDescription
	}
	return nil
}

// For memory tracking.
type MemoryStats struct {
	HostTempMemorySize             int64   `protobuf:"varint,1,opt,name=host_temp_memory_size,json=hostTempMemorySize,proto3" json:"host_temp_memory_size,omitempty"`
	DeviceTempMemorySize           int64   `protobuf:"varint,2,opt,name=device_temp_memory_size,json=deviceTempMemorySize,proto3" json:"device_temp_memory_size,omitempty"`
	HostPersistentMemorySize       int64   `protobuf:"varint,3,opt,name=host_persistent_memory_size,json=hostPersistentMemorySize,proto3" json:"host_persistent_memory_size,omitempty"`
	DevicePersistentMemorySize     int64   `protobuf:"varint,4,opt,name=device_persistent_memory_size,json=devicePersistentMemorySize,proto3" json:"device_persistent_memory_size,omitempty"`
	HostPersistentTensorAllocIds   []int64 `protobuf:"varint,5,rep,packed,name=host_persistent_tensor_alloc_ids,json=hostPersistentTensorAllocIds" json:"host_persistent_tensor_alloc_ids,omitempty"`
	DevicePersistentTensorAllocIds []int64 `protobuf:"varint,6,rep,packed,name=device_persistent_tensor_alloc_ids,json=devicePersistentTensorAllocIds" json:"device_persistent_tensor_alloc_ids,omitempty"`
}

func (m *MemoryStats) Reset()                    { *m = MemoryStats{} }
func (*MemoryStats) ProtoMessage()               {}
func (*MemoryStats) Descriptor() ([]byte, []int) { return fileDescriptorStepStats, []int{2} }

func (m *MemoryStats) GetHostTempMemorySize() int64 {
	if m != nil {
		return m.HostTempMemorySize
	}
	return 0
}

func (m *MemoryStats) GetDeviceTempMemorySize() int64 {
	if m != nil {
		return m.DeviceTempMemorySize
	}
	return 0
}

func (m *MemoryStats) GetHostPersistentMemorySize() int64 {
	if m != nil {
		return m.HostPersistentMemorySize
	}
	return 0
}

func (m *MemoryStats) GetDevicePersistentMemorySize() int64 {
	if m != nil {
		return m.DevicePersistentMemorySize
	}
	return 0
}

func (m *MemoryStats) GetHostPersistentTensorAllocIds() []int64 {
	if m != nil {
		return m.HostPersistentTensorAllocIds
	}
	return nil
}

func (m *MemoryStats) GetDevicePersistentTensorAllocIds() []int64 {
	if m != nil {
		return m.DevicePersistentTensorAllocIds
	}
	return nil
}

// Time/size stats recorded for a single execution of a graph node.
type NodeExecStats struct {
	// TODO(tucker): Use some more compact form of node identity than
	// the full string name.  Either all processes should agree on a
	// global id (cost_id?) for each node, or we should use a hash of
	// the name.
	NodeName         string                               `protobuf:"bytes,1,opt,name=node_name,json=nodeName,proto3" json:"node_name,omitempty"`
	AllStartMicros   int64                                `protobuf:"varint,2,opt,name=all_start_micros,json=allStartMicros,proto3" json:"all_start_micros,omitempty"`
	OpStartRelMicros int64                                `protobuf:"varint,3,opt,name=op_start_rel_micros,json=opStartRelMicros,proto3" json:"op_start_rel_micros,omitempty"`
	OpEndRelMicros   int64                                `protobuf:"varint,4,opt,name=op_end_rel_micros,json=opEndRelMicros,proto3" json:"op_end_rel_micros,omitempty"`
	AllEndRelMicros  int64                                `protobuf:"varint,5,opt,name=all_end_rel_micros,json=allEndRelMicros,proto3" json:"all_end_rel_micros,omitempty"`
	Memory           []*AllocatorMemoryUsed               `protobuf:"bytes,6,rep,name=memory" json:"memory,omitempty"`
	Output           []*NodeOutput                        `protobuf:"bytes,7,rep,name=output" json:"output,omitempty"`
	TimelineLabel    string                               `protobuf:"bytes,8,opt,name=timeline_label,json=timelineLabel,proto3" json:"timeline_label,omitempty"`
	ScheduledMicros  int64                                `protobuf:"varint,9,opt,name=scheduled_micros,json=scheduledMicros,proto3" json:"scheduled_micros,omitempty"`
	ThreadId         uint32                               `protobuf:"varint,10,opt,name=thread_id,json=threadId,proto3" json:"thread_id,omitempty"`
	ReferencedTensor []*tensorflow1.AllocationDescription `protobuf:"bytes,11,rep,name=referenced_tensor,json=referencedTensor" json:"referenced_tensor,omitempty"`
	MemoryStats      *MemoryStats                         `protobuf:"bytes,12,opt,name=memory_stats,json=memoryStats" json:"memory_stats,omitempty"`
}

func (m *NodeExecStats) Reset()                    { *m = NodeExecStats{} }
func (*NodeExecStats) ProtoMessage()               {}
func (*NodeExecStats) Descriptor() ([]byte, []int) { return fileDescriptorStepStats, []int{3} }

func (m *NodeExecStats) GetNodeName() string {
	if m != nil {
		return m.NodeName
	}
	return ""
}

func (m *NodeExecStats) GetAllStartMicros() int64 {
	if m != nil {
		return m.AllStartMicros
	}
	return 0
}

func (m *NodeExecStats) GetOpStartRelMicros() int64 {
	if m != nil {
		return m.OpStartRelMicros
	}
	return 0
}

func (m *NodeExecStats) GetOpEndRelMicros() int64 {
	if m != nil {
		return m.OpEndRelMicros
	}
	return 0
}

func (m *NodeExecStats) GetAllEndRelMicros() int64 {
	if m != nil {
		return m.AllEndRelMicros
	}
	return 0
}

func (m *NodeExecStats) GetMemory() []*AllocatorMemoryUsed {
	if m != nil {
		return m.Memory
	}
	return nil
}

func (m *NodeExecStats) GetOutput() []*NodeOutput {
	if m != nil {
		return m.Output
	}
	return nil
}

func (m *NodeExecStats) GetTimelineLabel() string {
	if m != nil {
		return m.TimelineLabel
	}
	return ""
}

func (m *NodeExecStats) GetScheduledMicros() int64 {
	if m != nil {
		return m.ScheduledMicros
	}
	return 0
}

func (m *NodeExecStats) GetThreadId() uint32 {
	if m != nil {
		return m.ThreadId
	}
	return 0
}

func (m *NodeExecStats) GetReferencedTensor() []*tensorflow1.AllocationDescription {
	if m != nil {
		return m.ReferencedTensor
	}
	return nil
}

func (m *NodeExecStats) GetMemoryStats() *MemoryStats {
	if m != nil {
		return m.MemoryStats
	}
	return nil
}

type DeviceStepStats struct {
	Device    string           `protobuf:"bytes,1,opt,name=device,proto3" json:"device,omitempty"`
	NodeStats []*NodeExecStats `protobuf:"bytes,2,rep,name=node_stats,json=nodeStats" json:"node_stats,omitempty"`
}

func (m *DeviceStepStats) Reset()                    { *m = DeviceStepStats{} }
func (*DeviceStepStats) ProtoMessage()               {}
func (*DeviceStepStats) Descriptor() ([]byte, []int) { return fileDescriptorStepStats, []int{4} }

func (m *DeviceStepStats) GetDevice() string {
	if m != nil {
		return m.Device
	}
	return ""
}

func (m *DeviceStepStats) GetNodeStats() []*NodeExecStats {
	if m != nil {
		return m.NodeStats
	}
	return nil
}

type StepStats struct {
	DevStats []*DeviceStepStats `protobuf:"bytes,1,rep,name=dev_stats,json=devStats" json:"dev_stats,omitempty"`
}

func (m *StepStats) Reset()                    { *m = StepStats{} }
func (*StepStats) ProtoMessage()               {}
func (*StepStats) Descriptor() ([]byte, []int) { return fileDescriptorStepStats, []int{5} }

func (m *StepStats) GetDevStats() []*DeviceStepStats {
	if m != nil {
		return m.DevStats
	}
	return nil
}

func init() {
	proto.RegisterType((*AllocatorMemoryUsed)(nil), "tensorflow.AllocatorMemoryUsed")
	proto.RegisterType((*NodeOutput)(nil), "tensorflow.NodeOutput")
	proto.RegisterType((*MemoryStats)(nil), "tensorflow.MemoryStats")
	proto.RegisterType((*NodeExecStats)(nil), "tensorflow.NodeExecStats")
	proto.RegisterType((*DeviceStepStats)(nil), "tensorflow.DeviceStepStats")
	proto.RegisterType((*StepStats)(nil), "tensorflow.StepStats")
}
func (this *AllocatorMemoryUsed) Equal(that interface{}) bool {
	if that == nil {
		if this == nil {
			return true
		}
		return false
	}

	that1, ok := that.(*AllocatorMemoryUsed)
	if !ok {
		that2, ok := that.(AllocatorMemoryUsed)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		if this == nil {
			return true
		}
		return false
	} else if this == nil {
		return false
	}
	if this.AllocatorName != that1.AllocatorName {
		return false
	}
	if this.TotalBytes != that1.TotalBytes {
		return false
	}
	if this.PeakBytes != that1.PeakBytes {
		return false
	}
	if this.LiveBytes != that1.LiveBytes {
		return false
	}
	if this.AllocatorBytesInUse != that1.AllocatorBytesInUse {
		return false
	}
	return true
}
func (this *NodeOutput) Equal(that interface{}) bool {
	if that == nil {
		if this == nil {
			return true
		}
		return false
	}

	that1, ok := that.(*NodeOutput)
	if !ok {
		that2, ok := that.(NodeOutput)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		if this == nil {
			return true
		}
		return false
	} else if this == nil {
		return false
	}
	if this.Slot != that1.Slot {
		return false
	}
	if !this.TensorDescription.Equal(that1.TensorDescription) {
		return false
	}
	return true
}
func (this *MemoryStats) Equal(that interface{}) bool {
	if that == nil {
		if this == nil {
			return true
		}
		return false
	}

	that1, ok := that.(*MemoryStats)
	if !ok {
		that2, ok := that.(MemoryStats)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		if this == nil {
			return true
		}
		return false
	} else if this == nil {
		return false
	}
	if this.HostTempMemorySize != that1.HostTempMemorySize {
		return false
	}
	if this.DeviceTempMemorySize != that1.DeviceTempMemorySize {
		return false
	}
	if this.HostPersistentMemorySize != that1.HostPersistentMemorySize {
		return false
	}
	if this.DevicePersistentMemorySize != that1.DevicePersistentMemorySize {
		return false
	}
	if len(this.HostPersistentTensorAllocIds) != len(that1.HostPersistentTensorAllocIds) {
		return false
	}
	for i := range this.HostPersistentTensorAllocIds {
		if this.HostPersistentTensorAllocIds[i] != that1.HostPersistentTensorAllocIds[i] {
			return false
		}
	}
	if len(this.DevicePersistentTensorAllocIds) != len(that1.DevicePersistentTensorAllocIds) {
		return false
	}
	for i := range this.DevicePersistentTensorAllocIds {
		if this.DevicePersistentTensorAllocIds[i] != that1.DevicePersistentTensorAllocIds[i] {
			return false
		}
	}
	return true
}
func (this *NodeExecStats) Equal(that interface{}) bool {
	if that == nil {
		if this == nil {
			return true
		}
		return false
	}

	that1, ok := that.(*NodeExecStats)
	if !ok {
		that2, ok := that.(NodeExecStats)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		if this == nil {
			return true
		}
		return false
	} else if this == nil {
		return false
	}
	if this.NodeName != that1.NodeName {
		return false
	}
	if this.AllStartMicros != that1.AllStartMicros {
		return false
	}
	if this.OpStartRelMicros != that1.OpStartRelMicros {
		return false
	}
	if this.OpEndRelMicros != that1.OpEndRelMicros {
		return false
	}
	if this.AllEndRelMicros != that1.AllEndRelMicros {
		return false
	}
	if len(this.Memory) != len(that1.Memory) {
		return false
	}
	for i := range this.Memory {
		if !this.Memory[i].Equal(that1.Memory[i]) {
			return false
		}
	}
	if len(this.Output) != len(that1.Output) {
		return false
	}
	for i := range this.Output {
		if !this.Output[i].Equal(that1.Output[i]) {
			return false
		}
	}
	if this.TimelineLabel != that1.TimelineLabel {
		return false
	}
	if this.ScheduledMicros != that1.ScheduledMicros {
		return false
	}
	if this.ThreadId != that1.ThreadId {
		return false
	}
	if len(this.ReferencedTensor) != len(that1.ReferencedTensor) {
		return false
	}
	for i := range this.ReferencedTensor {
		if !this.ReferencedTensor[i].Equal(that1.ReferencedTensor[i]) {
			return false
		}
	}
	if !this.MemoryStats.Equal(that1.MemoryStats) {
		return false
	}
	return true
}
func (this *DeviceStepStats) Equal(that interface{}) bool {
	if that == nil {
		if this == nil {
			return true
		}
		return false
	}

	that1, ok := that.(*DeviceStepStats)
	if !ok {
		that2, ok := that.(DeviceStepStats)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		if this == nil {
			return true
		}
		return false
	} else if this == nil {
		return false
	}
	if this.Device != that1.Device {
		return false
	}
	if len(this.NodeStats) != len(that1.NodeStats) {
		return false
	}
	for i := range this.NodeStats {
		if !this.NodeStats[i].Equal(that1.NodeStats[i]) {
			return false
		}
	}
	return true
}
func (this *StepStats) Equal(that interface{}) bool {
	if that == nil {
		if this == nil {
			return true
		}
		return false
	}

	that1, ok := that.(*StepStats)
	if !ok {
		that2, ok := that.(StepStats)
		if ok {
			that1 = &that2
		} else {
			return false
		}
	}
	if that1 == nil {
		if this == nil {
			return true
		}
		return false
	} else if this == nil {
		return false
	}
	if len(this.DevStats) != len(that1.DevStats) {
		return false
	}
	for i := range this.DevStats {
		if !this.DevStats[i].Equal(that1.DevStats[i]) {
			return false
		}
	}
	return true
}
func (this *AllocatorMemoryUsed) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 9)
	s = append(s, "&tensorflow.AllocatorMemoryUsed{")
	s = append(s, "AllocatorName: "+fmt.Sprintf("%#v", this.AllocatorName)+",\n")
	s = append(s, "TotalBytes: "+fmt.Sprintf("%#v", this.TotalBytes)+",\n")
	s = append(s, "PeakBytes: "+fmt.Sprintf("%#v", this.PeakBytes)+",\n")
	s = append(s, "LiveBytes: "+fmt.Sprintf("%#v", this.LiveBytes)+",\n")
	s = append(s, "AllocatorBytesInUse: "+fmt.Sprintf("%#v", this.AllocatorBytesInUse)+",\n")
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *NodeOutput) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 6)
	s = append(s, "&tensorflow.NodeOutput{")
	s = append(s, "Slot: "+fmt.Sprintf("%#v", this.Slot)+",\n")
	if this.TensorDescription != nil {
		s = append(s, "TensorDescription: "+fmt.Sprintf("%#v", this.TensorDescription)+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *MemoryStats) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 10)
	s = append(s, "&tensorflow.MemoryStats{")
	s = append(s, "HostTempMemorySize: "+fmt.Sprintf("%#v", this.HostTempMemorySize)+",\n")
	s = append(s, "DeviceTempMemorySize: "+fmt.Sprintf("%#v", this.DeviceTempMemorySize)+",\n")
	s = append(s, "HostPersistentMemorySize: "+fmt.Sprintf("%#v", this.HostPersistentMemorySize)+",\n")
	s = append(s, "DevicePersistentMemorySize: "+fmt.Sprintf("%#v", this.DevicePersistentMemorySize)+",\n")
	s = append(s, "HostPersistentTensorAllocIds: "+fmt.Sprintf("%#v", this.HostPersistentTensorAllocIds)+",\n")
	s = append(s, "DevicePersistentTensorAllocIds: "+fmt.Sprintf("%#v", this.DevicePersistentTensorAllocIds)+",\n")
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *NodeExecStats) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 16)
	s = append(s, "&tensorflow.NodeExecStats{")
	s = append(s, "NodeName: "+fmt.Sprintf("%#v", this.NodeName)+",\n")
	s = append(s, "AllStartMicros: "+fmt.Sprintf("%#v", this.AllStartMicros)+",\n")
	s = append(s, "OpStartRelMicros: "+fmt.Sprintf("%#v", this.OpStartRelMicros)+",\n")
	s = append(s, "OpEndRelMicros: "+fmt.Sprintf("%#v", this.OpEndRelMicros)+",\n")
	s = append(s, "AllEndRelMicros: "+fmt.Sprintf("%#v", this.AllEndRelMicros)+",\n")
	if this.Memory != nil {
		s = append(s, "Memory: "+fmt.Sprintf("%#v", this.Memory)+",\n")
	}
	if this.Output != nil {
		s = append(s, "Output: "+fmt.Sprintf("%#v", this.Output)+",\n")
	}
	s = append(s, "TimelineLabel: "+fmt.Sprintf("%#v", this.TimelineLabel)+",\n")
	s = append(s, "ScheduledMicros: "+fmt.Sprintf("%#v", this.ScheduledMicros)+",\n")
	s = append(s, "ThreadId: "+fmt.Sprintf("%#v", this.ThreadId)+",\n")
	if this.ReferencedTensor != nil {
		s = append(s, "ReferencedTensor: "+fmt.Sprintf("%#v", this.ReferencedTensor)+",\n")
	}
	if this.MemoryStats != nil {
		s = append(s, "MemoryStats: "+fmt.Sprintf("%#v", this.MemoryStats)+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *DeviceStepStats) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 6)
	s = append(s, "&tensorflow.DeviceStepStats{")
	s = append(s, "Device: "+fmt.Sprintf("%#v", this.Device)+",\n")
	if this.NodeStats != nil {
		s = append(s, "NodeStats: "+fmt.Sprintf("%#v", this.NodeStats)+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func (this *StepStats) GoString() string {
	if this == nil {
		return "nil"
	}
	s := make([]string, 0, 5)
	s = append(s, "&tensorflow.StepStats{")
	if this.DevStats != nil {
		s = append(s, "DevStats: "+fmt.Sprintf("%#v", this.DevStats)+",\n")
	}
	s = append(s, "}")
	return strings.Join(s, "")
}
func valueToGoStringStepStats(v interface{}, typ string) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("func(v %v) *%v { return &v } ( %#v )", typ, typ, pv)
}
func (m *AllocatorMemoryUsed) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AllocatorMemoryUsed) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.AllocatorName) > 0 {
		dAtA[i] = 0xa
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(len(m.AllocatorName)))
		i += copy(dAtA[i:], m.AllocatorName)
	}
	if m.TotalBytes != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.TotalBytes))
	}
	if m.PeakBytes != 0 {
		dAtA[i] = 0x18
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.PeakBytes))
	}
	if m.LiveBytes != 0 {
		dAtA[i] = 0x20
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.LiveBytes))
	}
	if m.AllocatorBytesInUse != 0 {
		dAtA[i] = 0x28
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.AllocatorBytesInUse))
	}
	return i, nil
}

func (m *NodeOutput) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NodeOutput) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Slot != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.Slot))
	}
	if m.TensorDescription != nil {
		dAtA[i] = 0x1a
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.TensorDescription.Size()))
		n1, err := m.TensorDescription.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n1
	}
	return i, nil
}

func (m *MemoryStats) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MemoryStats) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.HostTempMemorySize != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.HostTempMemorySize))
	}
	if m.DeviceTempMemorySize != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.DeviceTempMemorySize))
	}
	if m.HostPersistentMemorySize != 0 {
		dAtA[i] = 0x18
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.HostPersistentMemorySize))
	}
	if m.DevicePersistentMemorySize != 0 {
		dAtA[i] = 0x20
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.DevicePersistentMemorySize))
	}
	if len(m.HostPersistentTensorAllocIds) > 0 {
		dAtA3 := make([]byte, len(m.HostPersistentTensorAllocIds)*10)
		var j2 int
		for _, num1 := range m.HostPersistentTensorAllocIds {
			num := uint64(num1)
			for num >= 1<<7 {
				dAtA3[j2] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j2++
			}
			dAtA3[j2] = uint8(num)
			j2++
		}
		dAtA[i] = 0x2a
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(j2))
		i += copy(dAtA[i:], dAtA3[:j2])
	}
	if len(m.DevicePersistentTensorAllocIds) > 0 {
		dAtA5 := make([]byte, len(m.DevicePersistentTensorAllocIds)*10)
		var j4 int
		for _, num1 := range m.DevicePersistentTensorAllocIds {
			num := uint64(num1)
			for num >= 1<<7 {
				dAtA5[j4] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j4++
			}
			dAtA5[j4] = uint8(num)
			j4++
		}
		dAtA[i] = 0x32
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(j4))
		i += copy(dAtA[i:], dAtA5[:j4])
	}
	return i, nil
}

func (m *NodeExecStats) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NodeExecStats) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.NodeName) > 0 {
		dAtA[i] = 0xa
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(len(m.NodeName)))
		i += copy(dAtA[i:], m.NodeName)
	}
	if m.AllStartMicros != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.AllStartMicros))
	}
	if m.OpStartRelMicros != 0 {
		dAtA[i] = 0x18
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.OpStartRelMicros))
	}
	if m.OpEndRelMicros != 0 {
		dAtA[i] = 0x20
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.OpEndRelMicros))
	}
	if m.AllEndRelMicros != 0 {
		dAtA[i] = 0x28
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.AllEndRelMicros))
	}
	if len(m.Memory) > 0 {
		for _, msg := range m.Memory {
			dAtA[i] = 0x32
			i++
			i = encodeVarintStepStats(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if len(m.Output) > 0 {
		for _, msg := range m.Output {
			dAtA[i] = 0x3a
			i++
			i = encodeVarintStepStats(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if len(m.TimelineLabel) > 0 {
		dAtA[i] = 0x42
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(len(m.TimelineLabel)))
		i += copy(dAtA[i:], m.TimelineLabel)
	}
	if m.ScheduledMicros != 0 {
		dAtA[i] = 0x48
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.ScheduledMicros))
	}
	if m.ThreadId != 0 {
		dAtA[i] = 0x50
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.ThreadId))
	}
	if len(m.ReferencedTensor) > 0 {
		for _, msg := range m.ReferencedTensor {
			dAtA[i] = 0x5a
			i++
			i = encodeVarintStepStats(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if m.MemoryStats != nil {
		dAtA[i] = 0x62
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(m.MemoryStats.Size()))
		n6, err := m.MemoryStats.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n6
	}
	return i, nil
}

func (m *DeviceStepStats) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *DeviceStepStats) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Device) > 0 {
		dAtA[i] = 0xa
		i++
		i = encodeVarintStepStats(dAtA, i, uint64(len(m.Device)))
		i += copy(dAtA[i:], m.Device)
	}
	if len(m.NodeStats) > 0 {
		for _, msg := range m.NodeStats {
			dAtA[i] = 0x12
			i++
			i = encodeVarintStepStats(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	return i, nil
}

func (m *StepStats) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *StepStats) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.DevStats) > 0 {
		for _, msg := range m.DevStats {
			dAtA[i] = 0xa
			i++
			i = encodeVarintStepStats(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	return i, nil
}

func encodeFixed64StepStats(dAtA []byte, offset int, v uint64) int {
	dAtA[offset] = uint8(v)
	dAtA[offset+1] = uint8(v >> 8)
	dAtA[offset+2] = uint8(v >> 16)
	dAtA[offset+3] = uint8(v >> 24)
	dAtA[offset+4] = uint8(v >> 32)
	dAtA[offset+5] = uint8(v >> 40)
	dAtA[offset+6] = uint8(v >> 48)
	dAtA[offset+7] = uint8(v >> 56)
	return offset + 8
}
func encodeFixed32StepStats(dAtA []byte, offset int, v uint32) int {
	dAtA[offset] = uint8(v)
	dAtA[offset+1] = uint8(v >> 8)
	dAtA[offset+2] = uint8(v >> 16)
	dAtA[offset+3] = uint8(v >> 24)
	return offset + 4
}
func encodeVarintStepStats(dAtA []byte, offset int, v uint64) int {
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return offset + 1
}
func (m *AllocatorMemoryUsed) Size() (n int) {
	var l int
	_ = l
	l = len(m.AllocatorName)
	if l > 0 {
		n += 1 + l + sovStepStats(uint64(l))
	}
	if m.TotalBytes != 0 {
		n += 1 + sovStepStats(uint64(m.TotalBytes))
	}
	if m.PeakBytes != 0 {
		n += 1 + sovStepStats(uint64(m.PeakBytes))
	}
	if m.LiveBytes != 0 {
		n += 1 + sovStepStats(uint64(m.LiveBytes))
	}
	if m.AllocatorBytesInUse != 0 {
		n += 1 + sovStepStats(uint64(m.AllocatorBytesInUse))
	}
	return n
}

func (m *NodeOutput) Size() (n int) {
	var l int
	_ = l
	if m.Slot != 0 {
		n += 1 + sovStepStats(uint64(m.Slot))
	}
	if m.TensorDescription != nil {
		l = m.TensorDescription.Size()
		n += 1 + l + sovStepStats(uint64(l))
	}
	return n
}

func (m *MemoryStats) Size() (n int) {
	var l int
	_ = l
	if m.HostTempMemorySize != 0 {
		n += 1 + sovStepStats(uint64(m.HostTempMemorySize))
	}
	if m.DeviceTempMemorySize != 0 {
		n += 1 + sovStepStats(uint64(m.DeviceTempMemorySize))
	}
	if m.HostPersistentMemorySize != 0 {
		n += 1 + sovStepStats(uint64(m.HostPersistentMemorySize))
	}
	if m.DevicePersistentMemorySize != 0 {
		n += 1 + sovStepStats(uint64(m.DevicePersistentMemorySize))
	}
	if len(m.HostPersistentTensorAllocIds) > 0 {
		l = 0
		for _, e := range m.HostPersistentTensorAllocIds {
			l += sovStepStats(uint64(e))
		}
		n += 1 + sovStepStats(uint64(l)) + l
	}
	if len(m.DevicePersistentTensorAllocIds) > 0 {
		l = 0
		for _, e := range m.DevicePersistentTensorAllocIds {
			l += sovStepStats(uint64(e))
		}
		n += 1 + sovStepStats(uint64(l)) + l
	}
	return n
}

func (m *NodeExecStats) Size() (n int) {
	var l int
	_ = l
	l = len(m.NodeName)
	if l > 0 {
		n += 1 + l + sovStepStats(uint64(l))
	}
	if m.AllStartMicros != 0 {
		n += 1 + sovStepStats(uint64(m.AllStartMicros))
	}
	if m.OpStartRelMicros != 0 {
		n += 1 + sovStepStats(uint64(m.OpStartRelMicros))
	}
	if m.OpEndRelMicros != 0 {
		n += 1 + sovStepStats(uint64(m.OpEndRelMicros))
	}
	if m.AllEndRelMicros != 0 {
		n += 1 + sovStepStats(uint64(m.AllEndRelMicros))
	}
	if len(m.Memory) > 0 {
		for _, e := range m.Memory {
			l = e.Size()
			n += 1 + l + sovStepStats(uint64(l))
		}
	}
	if len(m.Output) > 0 {
		for _, e := range m.Output {
			l = e.Size()
			n += 1 + l + sovStepStats(uint64(l))
		}
	}
	l = len(m.TimelineLabel)
	if l > 0 {
		n += 1 + l + sovStepStats(uint64(l))
	}
	if m.ScheduledMicros != 0 {
		n += 1 + sovStepStats(uint64(m.ScheduledMicros))
	}
	if m.ThreadId != 0 {
		n += 1 + sovStepStats(uint64(m.ThreadId))
	}
	if len(m.ReferencedTensor) > 0 {
		for _, e := range m.ReferencedTensor {
			l = e.Size()
			n += 1 + l + sovStepStats(uint64(l))
		}
	}
	if m.MemoryStats != nil {
		l = m.MemoryStats.Size()
		n += 1 + l + sovStepStats(uint64(l))
	}
	return n
}

func (m *DeviceStepStats) Size() (n int) {
	var l int
	_ = l
	l = len(m.Device)
	if l > 0 {
		n += 1 + l + sovStepStats(uint64(l))
	}
	if len(m.NodeStats) > 0 {
		for _, e := range m.NodeStats {
			l = e.Size()
			n += 1 + l + sovStepStats(uint64(l))
		}
	}
	return n
}

func (m *StepStats) Size() (n int) {
	var l int
	_ = l
	if len(m.DevStats) > 0 {
		for _, e := range m.DevStats {
			l = e.Size()
			n += 1 + l + sovStepStats(uint64(l))
		}
	}
	return n
}

func sovStepStats(x uint64) (n int) {
	for {
		n++
		x >>= 7
		if x == 0 {
			break
		}
	}
	return n
}
func sozStepStats(x uint64) (n int) {
	return sovStepStats(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (this *AllocatorMemoryUsed) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&AllocatorMemoryUsed{`,
		`AllocatorName:` + fmt.Sprintf("%v", this.AllocatorName) + `,`,
		`TotalBytes:` + fmt.Sprintf("%v", this.TotalBytes) + `,`,
		`PeakBytes:` + fmt.Sprintf("%v", this.PeakBytes) + `,`,
		`LiveBytes:` + fmt.Sprintf("%v", this.LiveBytes) + `,`,
		`AllocatorBytesInUse:` + fmt.Sprintf("%v", this.AllocatorBytesInUse) + `,`,
		`}`,
	}, "")
	return s
}
func (this *NodeOutput) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&NodeOutput{`,
		`Slot:` + fmt.Sprintf("%v", this.Slot) + `,`,
		`TensorDescription:` + strings.Replace(fmt.Sprintf("%v", this.TensorDescription), "TensorDescription", "tensorflow4.TensorDescription", 1) + `,`,
		`}`,
	}, "")
	return s
}
func (this *MemoryStats) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&MemoryStats{`,
		`HostTempMemorySize:` + fmt.Sprintf("%v", this.HostTempMemorySize) + `,`,
		`DeviceTempMemorySize:` + fmt.Sprintf("%v", this.DeviceTempMemorySize) + `,`,
		`HostPersistentMemorySize:` + fmt.Sprintf("%v", this.HostPersistentMemorySize) + `,`,
		`DevicePersistentMemorySize:` + fmt.Sprintf("%v", this.DevicePersistentMemorySize) + `,`,
		`HostPersistentTensorAllocIds:` + fmt.Sprintf("%v", this.HostPersistentTensorAllocIds) + `,`,
		`DevicePersistentTensorAllocIds:` + fmt.Sprintf("%v", this.DevicePersistentTensorAllocIds) + `,`,
		`}`,
	}, "")
	return s
}
func (this *NodeExecStats) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&NodeExecStats{`,
		`NodeName:` + fmt.Sprintf("%v", this.NodeName) + `,`,
		`AllStartMicros:` + fmt.Sprintf("%v", this.AllStartMicros) + `,`,
		`OpStartRelMicros:` + fmt.Sprintf("%v", this.OpStartRelMicros) + `,`,
		`OpEndRelMicros:` + fmt.Sprintf("%v", this.OpEndRelMicros) + `,`,
		`AllEndRelMicros:` + fmt.Sprintf("%v", this.AllEndRelMicros) + `,`,
		`Memory:` + strings.Replace(fmt.Sprintf("%v", this.Memory), "AllocatorMemoryUsed", "AllocatorMemoryUsed", 1) + `,`,
		`Output:` + strings.Replace(fmt.Sprintf("%v", this.Output), "NodeOutput", "NodeOutput", 1) + `,`,
		`TimelineLabel:` + fmt.Sprintf("%v", this.TimelineLabel) + `,`,
		`ScheduledMicros:` + fmt.Sprintf("%v", this.ScheduledMicros) + `,`,
		`ThreadId:` + fmt.Sprintf("%v", this.ThreadId) + `,`,
		`ReferencedTensor:` + strings.Replace(fmt.Sprintf("%v", this.ReferencedTensor), "AllocationDescription", "tensorflow1.AllocationDescription", 1) + `,`,
		`MemoryStats:` + strings.Replace(fmt.Sprintf("%v", this.MemoryStats), "MemoryStats", "MemoryStats", 1) + `,`,
		`}`,
	}, "")
	return s
}
func (this *DeviceStepStats) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&DeviceStepStats{`,
		`Device:` + fmt.Sprintf("%v", this.Device) + `,`,
		`NodeStats:` + strings.Replace(fmt.Sprintf("%v", this.NodeStats), "NodeExecStats", "NodeExecStats", 1) + `,`,
		`}`,
	}, "")
	return s
}
func (this *StepStats) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&StepStats{`,
		`DevStats:` + strings.Replace(fmt.Sprintf("%v", this.DevStats), "DeviceStepStats", "DeviceStepStats", 1) + `,`,
		`}`,
	}, "")
	return s
}
func valueToStringStepStats(v interface{}) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("*%v", pv)
}
func (m *AllocatorMemoryUsed) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowStepStats
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AllocatorMemoryUsed: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AllocatorMemoryUsed: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field AllocatorName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthStepStats
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.AllocatorName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field TotalBytes", wireType)
			}
			m.TotalBytes = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.TotalBytes |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field PeakBytes", wireType)
			}
			m.PeakBytes = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.PeakBytes |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field LiveBytes", wireType)
			}
			m.LiveBytes = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.LiveBytes |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field AllocatorBytesInUse", wireType)
			}
			m.AllocatorBytesInUse = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.AllocatorBytesInUse |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipStepStats(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthStepStats
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NodeOutput) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowStepStats
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NodeOutput: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NodeOutput: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Slot", wireType)
			}
			m.Slot = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Slot |= (int32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TensorDescription", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthStepStats
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.TensorDescription == nil {
				m.TensorDescription = &tensorflow4.TensorDescription{}
			}
			if err := m.TensorDescription.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipStepStats(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthStepStats
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MemoryStats) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowStepStats
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MemoryStats: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MemoryStats: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HostTempMemorySize", wireType)
			}
			m.HostTempMemorySize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.HostTempMemorySize |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DeviceTempMemorySize", wireType)
			}
			m.DeviceTempMemorySize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DeviceTempMemorySize |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HostPersistentMemorySize", wireType)
			}
			m.HostPersistentMemorySize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.HostPersistentMemorySize |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field DevicePersistentMemorySize", wireType)
			}
			m.DevicePersistentMemorySize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.DevicePersistentMemorySize |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType == 0 {
				var v int64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowStepStats
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (int64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.HostPersistentTensorAllocIds = append(m.HostPersistentTensorAllocIds, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowStepStats
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthStepStats
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v int64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowStepStats
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (int64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.HostPersistentTensorAllocIds = append(m.HostPersistentTensorAllocIds, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field HostPersistentTensorAllocIds", wireType)
			}
		case 6:
			if wireType == 0 {
				var v int64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowStepStats
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (int64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.DevicePersistentTensorAllocIds = append(m.DevicePersistentTensorAllocIds, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowStepStats
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthStepStats
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v int64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowStepStats
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (int64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.DevicePersistentTensorAllocIds = append(m.DevicePersistentTensorAllocIds, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DevicePersistentTensorAllocIds", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipStepStats(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthStepStats
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NodeExecStats) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowStepStats
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NodeExecStats: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NodeExecStats: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field NodeName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthStepStats
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.NodeName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field AllStartMicros", wireType)
			}
			m.AllStartMicros = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.AllStartMicros |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OpStartRelMicros", wireType)
			}
			m.OpStartRelMicros = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OpStartRelMicros |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OpEndRelMicros", wireType)
			}
			m.OpEndRelMicros = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OpEndRelMicros |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field AllEndRelMicros", wireType)
			}
			m.AllEndRelMicros = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.AllEndRelMicros |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 6:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Memory", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthStepStats
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Memory = append(m.Memory, &AllocatorMemoryUsed{})
			if err := m.Memory[len(m.Memory)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 7:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Output", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthStepStats
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Output = append(m.Output, &NodeOutput{})
			if err := m.Output[len(m.Output)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 8:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TimelineLabel", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthStepStats
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.TimelineLabel = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 9:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ScheduledMicros", wireType)
			}
			m.ScheduledMicros = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ScheduledMicros |= (int64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 10:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ThreadId", wireType)
			}
			m.ThreadId = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.ThreadId |= (uint32(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReferencedTensor", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthStepStats
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ReferencedTensor = append(m.ReferencedTensor, &tensorflow1.AllocationDescription{})
			if err := m.ReferencedTensor[len(m.ReferencedTensor)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 12:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field MemoryStats", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthStepStats
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.MemoryStats == nil {
				m.MemoryStats = &MemoryStats{}
			}
			if err := m.MemoryStats.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipStepStats(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthStepStats
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *DeviceStepStats) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowStepStats
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: DeviceStepStats: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: DeviceStepStats: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Device", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthStepStats
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Device = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field NodeStats", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthStepStats
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.NodeStats = append(m.NodeStats, &NodeExecStats{})
			if err := m.NodeStats[len(m.NodeStats)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipStepStats(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthStepStats
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *StepStats) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowStepStats
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: StepStats: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: StepStats: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field DevStats", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthStepStats
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.DevStats = append(m.DevStats, &DeviceStepStats{})
			if err := m.DevStats[len(m.DevStats)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipStepStats(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthStepStats
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipStepStats(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowStepStats
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
			return iNdEx, nil
		case 1:
			iNdEx += 8
			return iNdEx, nil
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowStepStats
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			iNdEx += length
			if length < 0 {
				return 0, ErrInvalidLengthStepStats
			}
			return iNdEx, nil
		case 3:
			for {
				var innerWire uint64
				var start int = iNdEx
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return 0, ErrIntOverflowStepStats
					}
					if iNdEx >= l {
						return 0, io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					innerWire |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				innerWireType := int(innerWire & 0x7)
				if innerWireType == 4 {
					break
				}
				next, err := skipStepStats(dAtA[start:])
				if err != nil {
					return 0, err
				}
				iNdEx = start + next
			}
			return iNdEx, nil
		case 4:
			return iNdEx, nil
		case 5:
			iNdEx += 4
			return iNdEx, nil
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
	}
	panic("unreachable")
}

var (
	ErrInvalidLengthStepStats = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowStepStats   = fmt.Errorf("proto: integer overflow")
)

func init() {
	proto.RegisterFile("protobuf/tensorflow/core/framework/step_stats.proto", fileDescriptorStepStats)
}

var fileDescriptorStepStats = []byte{
	// 820 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x74, 0x55, 0x41, 0x6f, 0x1b, 0x45,
	0x14, 0xce, 0xd4, 0x89, 0x89, 0x9f, 0x9b, 0x26, 0x99, 0x40, 0xba, 0x24, 0x64, 0x6b, 0x2c, 0x21,
	0xb9, 0x42, 0xd8, 0x22, 0x11, 0x50, 0x21, 0x71, 0x68, 0xd4, 0x20, 0x05, 0xb5, 0x21, 0xda, 0xb4,
	0x37, 0xa4, 0xd5, 0x7a, 0xe7, 0x99, 0xac, 0x3a, 0xbb, 0xb3, 0x9a, 0x19, 0xbb, 0xb4, 0x27, 0xfe,
	0x00, 0x12, 0x3f, 0x83, 0xbf, 0xc1, 0x8d, 0x63, 0x8e, 0x1c, 0x89, 0xb9, 0x70, 0xcc, 0x91, 0x63,
	0x35, 0x33, 0xeb, 0xdd, 0xb5, 0x9d, 0xdc, 0xd6, 0xdf, 0xfb, 0xde, 0x37, 0x9f, 0xdf, 0x7c, 0x6f,
	0x17, 0x8e, 0x72, 0x29, 0xb4, 0x18, 0x8e, 0x47, 0x03, 0x8d, 0x99, 0x12, 0x72, 0xc4, 0xc5, 0x9b,
	0x41, 0x2c, 0x24, 0x0e, 0x46, 0x32, 0x4a, 0xf1, 0x8d, 0x90, 0xaf, 0x07, 0x4a, 0x63, 0x1e, 0x2a,
	0x1d, 0x69, 0xd5, 0xb7, 0x6c, 0x0a, 0x15, 0x77, 0xef, 0xeb, 0xbb, 0xfb, 0x22, 0xce, 0x45, 0x1c,
	0xe9, 0x44, 0x64, 0x21, 0x43, 0x15, 0xcb, 0x24, 0x37, 0xcf, 0x4e, 0x63, 0xef, 0xf0, 0xee, 0x3e,
	0x57, 0x59, 0xee, 0xe9, 0x5e, 0x11, 0xd8, 0x79, 0xea, 0x44, 0x85, 0x7c, 0x81, 0xa9, 0x90, 0x6f,
	0x5f, 0x29, 0x64, 0xf4, 0x33, 0x78, 0x10, 0xcd, 0xe0, 0x30, 0x8b, 0x52, 0xf4, 0x48, 0x87, 0xf4,
	0x5a, 0xc1, 0x46, 0x89, 0x9e, 0x45, 0x29, 0xd2, 0x47, 0xd0, 0xd6, 0x42, 0x47, 0x3c, 0x1c, 0xbe,
	0xd5, 0xa8, 0xbc, 0x7b, 0x1d, 0xd2, 0x6b, 0x04, 0x60, 0xa1, 0x63, 0x83, 0xd0, 0x03, 0x80, 0x1c,
	0xa3, 0xd7, 0x45, 0xbd, 0x61, 0xeb, 0x2d, 0x83, 0x94, 0x65, 0x9e, 0x4c, 0xb0, 0x28, 0xaf, 0xba,
	0xb2, 0x41, 0x5c, 0xf9, 0x08, 0x76, 0x2b, 0x17, 0x96, 0x13, 0x26, 0x59, 0x38, 0x56, 0xe8, 0xad,
	0x59, 0xea, 0x4e, 0x59, 0xb5, 0xfc, 0xd3, 0xec, 0x95, 0xc2, 0x6e, 0x06, 0x70, 0x26, 0x18, 0xfe,
	0x38, 0xd6, 0xf9, 0x58, 0x53, 0x0a, 0xab, 0x8a, 0x0b, 0x6d, 0xed, 0xaf, 0x05, 0xf6, 0x99, 0x3e,
	0x07, 0xba, 0x3c, 0x10, 0x6b, 0xae, 0x7d, 0x78, 0xd0, 0xaf, 0xa6, 0xd8, 0x7f, 0x69, 0x1f, 0x9f,
	0x55, 0xa4, 0x60, 0x5b, 0x2f, 0x42, 0xdd, 0xdf, 0x1a, 0xd0, 0x76, 0x93, 0xbb, 0x30, 0x17, 0x4a,
	0xbf, 0x84, 0x8f, 0x2e, 0x85, 0xd2, 0xa1, 0xc6, 0x34, 0x0f, 0x53, 0x5b, 0x08, 0x55, 0xf2, 0xce,
	0x4d, 0xb0, 0x11, 0x50, 0x53, 0x7c, 0x89, 0x69, 0x5e, 0xf4, 0x24, 0xef, 0x90, 0x7e, 0x05, 0x0f,
	0x19, 0x4e, 0x92, 0x18, 0x97, 0x9b, 0xdc, 0x48, 0x3f, 0x74, 0xe5, 0x85, 0xb6, 0xef, 0x60, 0xdf,
	0x9e, 0x94, 0xa3, 0x54, 0x89, 0xd2, 0x98, 0xe9, 0xb9, 0x56, 0x37, 0x6d, 0xcf, 0x50, 0xce, 0x4b,
	0x46, 0xad, 0xfd, 0x29, 0x1c, 0x14, 0xa7, 0xde, 0x21, 0xe0, 0xee, 0x63, 0xcf, 0x91, 0x6e, 0x95,
	0xf8, 0x1e, 0x3a, 0x8b, 0x0e, 0x8a, 0xc9, 0xda, 0x9b, 0x09, 0x13, 0xa6, 0xbc, 0xb5, 0x4e, 0xa3,
	0xd7, 0x08, 0x3e, 0x99, 0xb7, 0xe1, 0x26, 0x6b, 0x93, 0x77, 0xca, 0x14, 0xfd, 0x01, 0xba, 0xcb,
	0x56, 0x96, 0x94, 0x9a, 0x56, 0xc9, 0x5f, 0xf4, 0x33, 0xaf, 0xd5, 0xfd, 0x73, 0x15, 0x36, 0x4c,
	0x00, 0x4e, 0x7e, 0xc1, 0xd8, 0xdd, 0xc8, 0x3e, 0xb4, 0x32, 0xc1, 0xb0, 0x9e, 0xe3, 0x75, 0x03,
	0xd8, 0x08, 0xf7, 0x60, 0x2b, 0xe2, 0xdc, 0x2c, 0xa3, 0xd4, 0x61, 0x9a, 0xc4, 0x52, 0xcc, 0x72,
	0x6c, 0x36, 0xe0, 0xc2, 0xc0, 0x2f, 0x2c, 0x4a, 0xbf, 0x80, 0x1d, 0x91, 0x17, 0x44, 0x89, 0x7c,
	0x46, 0x76, 0x63, 0xde, 0x12, 0xb9, 0xe5, 0x06, 0xc8, 0x0b, 0xfa, 0x63, 0xd8, 0x16, 0x79, 0x88,
	0x19, 0xab, 0x93, 0xdd, 0x48, 0x1f, 0x88, 0xfc, 0x24, 0x63, 0x15, 0xf5, 0x73, 0xa0, 0xc6, 0xc3,
	0x02, 0xd7, 0x65, 0x7c, 0x33, 0xe2, 0x7c, 0x8e, 0xfc, 0x0d, 0x34, 0xdd, 0x25, 0xd9, 0x79, 0xb4,
	0x0f, 0x1f, 0xd5, 0x13, 0x7b, 0xcb, 0x2e, 0x07, 0x05, 0x9d, 0xf6, 0xa1, 0x29, 0xec, 0x52, 0x78,
	0x1f, 0xd8, 0xc6, 0xdd, 0x7a, 0x63, 0xb5, 0x32, 0x41, 0xc1, 0x32, 0xef, 0x00, 0x9d, 0xa4, 0xc8,
	0x93, 0x0c, 0x43, 0x1e, 0x0d, 0x91, 0x7b, 0xeb, 0xee, 0x1d, 0x30, 0x43, 0x9f, 0x1b, 0x90, 0x3e,
	0x86, 0x2d, 0x15, 0x5f, 0x22, 0x1b, 0x73, 0x64, 0x33, 0xeb, 0x2d, 0x67, 0xbd, 0xc4, 0x0b, 0xeb,
	0xfb, 0xd0, 0xd2, 0x97, 0x12, 0x23, 0x16, 0x26, 0xcc, 0x83, 0x0e, 0xe9, 0x6d, 0x04, 0xeb, 0x0e,
	0x38, 0x65, 0xf4, 0x0c, 0xb6, 0x25, 0x8e, 0x50, 0x62, 0x16, 0x23, 0x2b, 0x2e, 0xdf, 0x6b, 0x5b,
	0xa7, 0x9f, 0xde, 0xf2, 0x17, 0x13, 0x91, 0xd5, 0x17, 0x73, 0xab, 0xea, 0x75, 0x79, 0xa0, 0xdf,
	0xc2, 0xfd, 0x59, 0x98, 0x4d, 0x0a, 0xbc, 0xfb, 0x76, 0xbf, 0x1f, 0xd6, 0xa5, 0x6a, 0x6b, 0x1b,
	0xb4, 0xd3, 0xea, 0x47, 0x37, 0x86, 0xcd, 0x67, 0x36, 0x65, 0x17, 0x1a, 0x73, 0x17, 0xa2, 0x5d,
	0x68, 0xba, 0xe0, 0x15, 0x09, 0x2a, 0x7e, 0xd1, 0x27, 0x00, 0x36, 0x5c, 0xee, 0x90, 0x7b, 0xd6,
	0xef, 0xc7, 0x8b, 0x93, 0x2d, 0xb3, 0x18, 0xd8, 0x24, 0xba, 0x43, 0x4e, 0xa0, 0x55, 0xc9, 0x3f,
	0x81, 0x16, 0xc3, 0x49, 0xa1, 0x42, 0xac, 0xca, 0x7e, 0x5d, 0x65, 0xc1, 0x4e, 0xb0, 0xce, 0x70,
	0x62, 0x9f, 0x8e, 0x7f, 0xba, 0xba, 0xf6, 0x57, 0xfe, 0xbe, 0xf6, 0x57, 0x6e, 0xae, 0x7d, 0xf2,
	0xeb, 0xd4, 0x27, 0x7f, 0x4c, 0x7d, 0xf2, 0xd7, 0xd4, 0x27, 0x57, 0x53, 0x9f, 0xfc, 0x33, 0xf5,
	0xc9, 0x7f, 0x53, 0x7f, 0xe5, 0x66, 0xea, 0x93, 0xdf, 0xff, 0xf5, 0x57, 0xc0, 0x13, 0xf2, 0xe7,
	0xba, 0x6e, 0xf9, 0x8d, 0x38, 0xde, 0x2c, 0xc5, 0xcf, 0xcd, 0xa7, 0x41, 0x9d, 0x93, 0xff, 0x09,
	0x19, 0x36, 0xed, 0x77, 0xe2, 0xe8, 0x7d, 0x00, 0x00, 0x00, 0xff, 0xff, 0x05, 0xce, 0x65, 0x0a,
	0xd6, 0x06, 0x00, 0x00,
}
